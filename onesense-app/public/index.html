<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="Web site created using create-react-app"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>OneSense App</title>
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root">
      <button id="recordButton" onclick="startRecording()">Start Recording</button>
      <button id="playButton">Play Recorded Audio</button>
      <audio id="audioPlayback"></audio>
    </div>
    <script>
      const recordButton = document.getElementById('recordButton');
      const playButton = document.getElementById('playButton');
      const audioPlayback = document.getElementById('audioPlayback');
      
      let audioChunks = [];
      let mediaRecorder = null;
      
      function startRecording() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          mediaRecorder = new MediaRecorder(stream);
          
          mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
          };
          
          mediaRecorder.onstop = () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/mp3' });
            const audioUrl = URL.createObjectURL(audioBlob);
            audioPlayback.src = audioUrl;
          };

          recordButton.innerText = 'Stop Recording';
          recordButton.onclick = stopRecording;

          // Clear the audioChunks array before starting a new recording
          audioChunks = [];

          mediaRecorder.start();
        });
    }

      function stopRecording() {
        mediaRecorder.stop();
        recordButton.innerText = 'Start Recording';
        recordButton.onclick = startRecording;

        const audioBlob = new Blob(audioChunks, { type: 'audio/mp3' });

        // Create a FormData object and append the audioBlob to it
        const formData = new FormData();
        formData.append('audio', audioBlob, 'recorded_audio.mp3');

        // Use fetch to send the FormData to your API endpoint
        fetch('your-api-endpoint', {
          method: 'POST',
          body: formData
        })
        .then(response => {
          if (!response.ok) {
            throw new Error('Failed to upload audio');
          }
          return response.json(); // assuming your API returns JSON
        })
        .then(data => {
          // Handle the response from your API
          console.log('Audio uploaded successfully:', data);
        })
        .catch(error => {
          console.error('Error uploading audio:', error);
        });
      }
      playButton.addEventListener('click', () => {
        audioPlayback.play();
      });
    </script>
  </body>
</html>
